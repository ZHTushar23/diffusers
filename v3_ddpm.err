[2023-12-23 18:30:56,058] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
[2023-12-23 18:30:56,058] torch.distributed.run: [WARNING] 
[2023-12-23 18:30:56,058] torch.distributed.run: [WARNING] *****************************************
[2023-12-23 18:30:56,058] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-12-23 18:30:56,058] torch.distributed.run: [WARNING] *****************************************
/home/ztushar1/.conda/envs/df/lib/python3.10/site-packages/accelerate/accelerator.py:384: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/home/ztushar1/.conda/envs/df/lib/python3.10/site-packages/accelerate/accelerator.py:384: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
/home/ztushar1/.conda/envs/df/lib/python3.10/site-packages/accelerate/accelerator.py:384: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
/home/ztushar1/.conda/envs/df/lib/python3.10/site-packages/accelerate/accelerator.py:384: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
  0%|          | 0/72 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/72 [00:00<?, ?it/s]/home/ztushar1/.conda/envs/df/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [32, 32, 1, 1], strides() = [32, 1, 32, 32]
bucket_view.sizes() = [32, 32, 1, 1], strides() = [32, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:320.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/ztushar1/.conda/envs/df/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [32, 32, 1, 1], strides() = [32, 1, 32, 32]
bucket_view.sizes() = [32, 32, 1, 1], strides() = [32, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:320.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/ztushar1/.conda/envs/df/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [32, 32, 1, 1], strides() = [32, 1, 32, 32]
bucket_view.sizes() = [32, 32, 1, 1], strides() = [32, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:320.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/ztushar1/.conda/envs/df/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [32, 32, 1, 1], strides() = [32, 1, 32, 32]
bucket_view.sizes() = [32, 32, 1, 1], strides() = [32, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:320.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Epoch 0:   1%|▏         | 1/72 [00:10<12:31, 10.58s/it]Epoch 0:   1%|▏         | 1/72 [00:10<12:31, 10.58s/it, loss=0.934, lr=8e-7, step=0]Epoch 0:   3%|▎         | 2/72 [00:13<06:45,  5.80s/it, loss=0.934, lr=8e-7, step=0]Epoch 0:   3%|▎         | 2/72 [00:13<06:45,  5.80s/it, loss=0.952, lr=1.6e-6, step=1]Epoch 0:   4%|▍         | 3/72 [00:15<04:46,  4.16s/it, loss=0.952, lr=1.6e-6, step=1]Epoch 0:   4%|▍         | 3/72 [00:15<04:46,  4.16s/it, loss=1.02, lr=2.4e-6, step=2] Epoch 0:   6%|▌         | 4/72 [00:17<03:52,  3.42s/it, loss=1.02, lr=2.4e-6, step=2]Epoch 0:   6%|▌         | 4/72 [00:17<03:52,  3.42s/it, loss=1.04, lr=3.2e-6, step=3]Epoch 0:   7%|▋         | 5/72 [00:19<03:20,  2.99s/it, loss=1.04, lr=3.2e-6, step=3]Epoch 0:   7%|▋         | 5/72 [00:19<03:20,  2.99s/it, loss=1.07, lr=4e-6, step=4]  Epoch 0:   8%|▊         | 6/72 [00:22<03:01,  2.75s/it, loss=1.07, lr=4e-6, step=4]Epoch 0:   8%|▊         | 6/72 [00:22<03:01,  2.75s/it, loss=0.949, lr=4.8e-6, step=5]Epoch 0:  10%|▉         | 7/72 [00:24<02:50,  2.62s/it, loss=0.949, lr=4.8e-6, step=5]Epoch 0:  10%|▉         | 7/72 [00:24<02:50,  2.62s/it, loss=0.942, lr=5.6e-6, step=6]Epoch 0:  11%|█         | 8/72 [00:26<02:40,  2.51s/it, loss=0.942, lr=5.6e-6, step=6]Epoch 0:  11%|█         | 8/72 [00:26<02:40,  2.51s/it, loss=0.931, lr=6.4e-6, step=7]Epoch 0:  12%|█▎        | 9/72 [00:28<02:32,  2.43s/it, loss=0.931, lr=6.4e-6, step=7]Epoch 0:  12%|█▎        | 9/72 [00:28<02:32,  2.43s/it, loss=0.923, lr=7.2e-6, step=8]Epoch 0:  14%|█▍        | 10/72 [00:31<02:27,  2.38s/it, loss=0.923, lr=7.2e-6, step=8]Epoch 0:  14%|█▍        | 10/72 [00:31<02:27,  2.38s/it, loss=0.918, lr=8e-6, step=9]  Epoch 0:  15%|█▌        | 11/72 [00:33<02:24,  2.37s/it, loss=0.918, lr=8e-6, step=9]Epoch 0:  15%|█▌        | 11/72 [00:33<02:24,  2.37s/it, loss=0.922, lr=8.8e-6, step=10]Epoch 0:  17%|█▋        | 12/72 [00:35<02:20,  2.34s/it, loss=0.922, lr=8.8e-6, step=10]Epoch 0:  17%|█▋        | 12/72 [00:35<02:20,  2.34s/it, loss=1.03, lr=9.6e-6, step=11] Epoch 0:  18%|█▊        | 13/72 [00:38<02:16,  2.31s/it, loss=1.03, lr=9.6e-6, step=11]Epoch 0:  18%|█▊        | 13/72 [00:38<02:16,  2.31s/it, loss=0.891, lr=1.04e-5, step=12]Epoch 0:  19%|█▉        | 14/72 [00:40<02:12,  2.29s/it, loss=0.891, lr=1.04e-5, step=12]Epoch 0:  19%|█▉        | 14/72 [00:40<02:12,  2.29s/it, loss=0.873, lr=1.12e-5, step=13]Epoch 0:  21%|██        | 15/72 [00:42<02:11,  2.30s/it, loss=0.873, lr=1.12e-5, step=13]Epoch 0:  21%|██        | 15/72 [00:42<02:11,  2.30s/it, loss=0.86, lr=1.2e-5, step=14]  Epoch 0:  22%|██▏       | 16/72 [00:44<02:09,  2.32s/it, loss=0.86, lr=1.2e-5, step=14]Epoch 0:  22%|██▏       | 16/72 [00:44<02:09,  2.32s/it, loss=0.858, lr=1.28e-5, step=15]Epoch 0:  24%|██▎       | 17/72 [00:47<02:06,  2.30s/it, loss=0.858, lr=1.28e-5, step=15]Epoch 0:  24%|██▎       | 17/72 [00:47<02:06,  2.30s/it, loss=0.841, lr=1.36e-5, step=16]Epoch 0:  25%|██▌       | 18/72 [00:49<02:02,  2.27s/it, loss=0.841, lr=1.36e-5, step=16]Epoch 0:  25%|██▌       | 18/72 [00:49<02:02,  2.27s/it, loss=0.832, lr=1.44e-5, step=17]Epoch 0:  26%|██▋       | 19/72 [00:51<02:00,  2.27s/it, loss=0.832, lr=1.44e-5, step=17]Epoch 0:  26%|██▋       | 19/72 [00:51<02:00,  2.27s/it, loss=0.891, lr=1.52e-5, step=18]Epoch 0:  28%|██▊       | 20/72 [00:53<01:57,  2.27s/it, loss=0.891, lr=1.52e-5, step=18]Epoch 0:  28%|██▊       | 20/72 [00:53<01:57,  2.27s/it, loss=0.885, lr=1.6e-5, step=19] Epoch 0:  29%|██▉       | 21/72 [00:56<01:56,  2.27s/it, loss=0.885, lr=1.6e-5, step=19]Epoch 0:  29%|██▉       | 21/72 [00:56<01:56,  2.27s/it, loss=0.781, lr=1.68e-5, step=20]Epoch 0:  31%|███       | 22/72 [00:58<01:54,  2.28s/it, loss=0.781, lr=1.68e-5, step=20]Epoch 0:  31%|███       | 22/72 [00:58<01:54,  2.28s/it, loss=0.775, lr=1.76e-5, step=21]Epoch 0:  32%|███▏      | 23/72 [01:00<01:51,  2.27s/it, loss=0.775, lr=1.76e-5, step=21]Epoch 0:  32%|███▏      | 23/72 [01:00<01:51,  2.27s/it, loss=0.753, lr=1.84e-5, step=22]Epoch 0:  33%|███▎      | 24/72 [01:03<01:49,  2.28s/it, loss=0.753, lr=1.84e-5, step=22]Epoch 0:  33%|███▎      | 24/72 [01:03<01:49,  2.28s/it, loss=0.733, lr=1.92e-5, step=23]Epoch 0:  35%|███▍      | 25/72 [01:05<01:47,  2.28s/it, loss=0.733, lr=1.92e-5, step=23]Epoch 0:  35%|███▍      | 25/72 [01:05<01:47,  2.28s/it, loss=0.727, lr=2e-5, step=24]   Epoch 0:  36%|███▌      | 26/72 [01:07<01:45,  2.29s/it, loss=0.727, lr=2e-5, step=24]Epoch 0:  36%|███▌      | 26/72 [01:07<01:45,  2.29s/it, loss=0.694, lr=2.08e-5, step=25]Epoch 0:  38%|███▊      | 27/72 [01:09<01:42,  2.27s/it, loss=0.694, lr=2.08e-5, step=25]Epoch 0:  38%|███▊      | 27/72 [01:09<01:42,  2.27s/it, loss=0.67, lr=2.16e-5, step=26] Epoch 0:  39%|███▉      | 28/72 [01:12<01:39,  2.25s/it, loss=0.67, lr=2.16e-5, step=26]Epoch 0:  39%|███▉      | 28/72 [01:12<01:39,  2.25s/it, loss=0.78, lr=2.24e-5, step=27]Epoch 0:  40%|████      | 29/72 [01:14<01:37,  2.27s/it, loss=0.78, lr=2.24e-5, step=27]Epoch 0:  40%|████      | 29/72 [01:14<01:37,  2.27s/it, loss=0.647, lr=2.32e-5, step=28]Epoch 0:  42%|████▏     | 30/72 [01:16<01:35,  2.27s/it, loss=0.647, lr=2.32e-5, step=28]Epoch 0:  42%|████▏     | 30/72 [01:16<01:35,  2.27s/it, loss=0.627, lr=2.4e-5, step=29] Epoch 0:  43%|████▎     | 31/72 [01:18<01:33,  2.27s/it, loss=0.627, lr=2.4e-5, step=29]Epoch 0:  43%|████▎     | 31/72 [01:18<01:33,  2.27s/it, loss=0.617, lr=2.48e-5, step=30]Epoch 0:  44%|████▍     | 32/72 [01:21<01:30,  2.27s/it, loss=0.617, lr=2.48e-5, step=30]Epoch 0:  44%|████▍     | 32/72 [01:21<01:30,  2.27s/it, loss=0.598, lr=2.56e-5, step=31]Epoch 0:  46%|████▌     | 33/72 [01:23<01:28,  2.26s/it, loss=0.598, lr=2.56e-5, step=31]Epoch 0:  46%|████▌     | 33/72 [01:23<01:28,  2.26s/it, loss=0.58, lr=2.64e-5, step=32] Epoch 0:  47%|████▋     | 34/72 [01:25<01:26,  2.29s/it, loss=0.58, lr=2.64e-5, step=32]Epoch 0:  47%|████▋     | 34/72 [01:25<01:26,  2.29s/it, loss=0.556, lr=2.72e-5, step=33]Epoch 0:  49%|████▊     | 35/72 [01:28<01:24,  2.29s/it, loss=0.556, lr=2.72e-5, step=33]Epoch 0:  49%|████▊     | 35/72 [01:28<01:24,  2.29s/it, loss=0.542, lr=2.8e-5, step=34] Epoch 0:  50%|█████     | 36/72 [01:30<01:22,  2.31s/it, loss=0.542, lr=2.8e-5, step=34]Epoch 0:  50%|█████     | 36/72 [01:30<01:22,  2.31s/it, loss=0.71, lr=2.88e-5, step=35]Epoch 0:  51%|█████▏    | 37/72 [01:32<01:20,  2.29s/it, loss=0.71, lr=2.88e-5, step=35]Epoch 0:  51%|█████▏    | 37/72 [01:32<01:20,  2.29s/it, loss=0.495, lr=2.96e-5, step=36]Epoch 0:  53%|█████▎    | 38/72 [01:35<01:18,  2.30s/it, loss=0.495, lr=2.96e-5, step=36]Epoch 0:  53%|█████▎    | 38/72 [01:35<01:18,  2.30s/it, loss=0.474, lr=3.04e-5, step=37]Epoch 0:  54%|█████▍    | 39/72 [01:37<01:16,  2.32s/it, loss=0.474, lr=3.04e-5, step=37]Epoch 0:  54%|█████▍    | 39/72 [01:37<01:16,  2.32s/it, loss=0.462, lr=3.12e-5, step=38]Epoch 0:  56%|█████▌    | 40/72 [01:39<01:13,  2.31s/it, loss=0.462, lr=3.12e-5, step=38]Epoch 0:  56%|█████▌    | 40/72 [01:39<01:13,  2.31s/it, loss=0.466, lr=3.2e-5, step=39] Epoch 0:  57%|█████▋    | 41/72 [01:41<01:11,  2.30s/it, loss=0.466, lr=3.2e-5, step=39]Epoch 0:  57%|█████▋    | 41/72 [01:41<01:11,  2.30s/it, loss=0.42, lr=3.28e-5, step=40]Epoch 0:  58%|█████▊    | 42/72 [01:44<01:08,  2.30s/it, loss=0.42, lr=3.28e-5, step=40]Epoch 0:  58%|█████▊    | 42/72 [01:44<01:08,  2.30s/it, loss=0.397, lr=3.36e-5, step=41]Epoch 0:  60%|█████▉    | 43/72 [01:46<01:06,  2.28s/it, loss=0.397, lr=3.36e-5, step=41]Epoch 0:  60%|█████▉    | 43/72 [01:46<01:06,  2.28s/it, loss=0.388, lr=3.44e-5, step=42]Epoch 0:  61%|██████    | 44/72 [01:48<01:03,  2.28s/it, loss=0.388, lr=3.44e-5, step=42]Epoch 0:  61%|██████    | 44/72 [01:48<01:03,  2.28s/it, loss=0.377, lr=3.52e-5, step=43]Epoch 0:  62%|██████▎   | 45/72 [01:51<01:01,  2.27s/it, loss=0.377, lr=3.52e-5, step=43]Epoch 0:  62%|██████▎   | 45/72 [01:51<01:01,  2.27s/it, loss=0.377, lr=3.6e-5, step=44] Epoch 0:  64%|██████▍   | 46/72 [01:53<00:58,  2.26s/it, loss=0.377, lr=3.6e-5, step=44]Epoch 0:  64%|██████▍   | 46/72 [01:53<00:58,  2.26s/it, loss=0.341, lr=3.68e-5, step=45]Epoch 0:  65%|██████▌   | 47/72 [01:55<00:57,  2.29s/it, loss=0.341, lr=3.68e-5, step=45]Epoch 0:  65%|██████▌   | 47/72 [01:55<00:57,  2.29s/it, loss=0.422, lr=3.76e-5, step=46]Epoch 0:  67%|██████▋   | 48/72 [01:57<00:54,  2.27s/it, loss=0.422, lr=3.76e-5, step=46]Epoch 0:  67%|██████▋   | 48/72 [01:57<00:54,  2.27s/it, loss=0.362, lr=3.84e-5, step=47]Epoch 0:  68%|██████▊   | 49/72 [02:00<00:52,  2.28s/it, loss=0.362, lr=3.84e-5, step=47]Epoch 0:  68%|██████▊   | 49/72 [02:00<00:52,  2.28s/it, loss=0.282, lr=3.92e-5, step=48]Epoch 0:  69%|██████▉   | 50/72 [02:02<00:50,  2.28s/it, loss=0.282, lr=3.92e-5, step=48]Epoch 0:  69%|██████▉   | 50/72 [02:02<00:50,  2.28s/it, loss=0.273, lr=4e-5, step=49]   Epoch 0:  71%|███████   | 51/72 [02:04<00:48,  2.29s/it, loss=0.273, lr=4e-5, step=49]Epoch 0:  71%|███████   | 51/72 [02:04<00:48,  2.29s/it, loss=0.259, lr=4.08e-5, step=50]Epoch 0:  72%|███████▏  | 52/72 [02:07<00:45,  2.29s/it, loss=0.259, lr=4.08e-5, step=50]Epoch 0:  72%|███████▏  | 52/72 [02:07<00:45,  2.29s/it, loss=0.24, lr=4.16e-5, step=51] Epoch 0:  74%|███████▎  | 53/72 [02:09<00:43,  2.28s/it, loss=0.24, lr=4.16e-5, step=51]Epoch 0:  74%|███████▎  | 53/72 [02:09<00:43,  2.28s/it, loss=0.226, lr=4.24e-5, step=52]Epoch 0:  75%|███████▌  | 54/72 [02:11<00:40,  2.27s/it, loss=0.226, lr=4.24e-5, step=52]Epoch 0:  75%|███████▌  | 54/72 [02:11<00:40,  2.27s/it, loss=0.215, lr=4.32e-5, step=53]Epoch 0:  76%|███████▋  | 55/72 [02:13<00:38,  2.27s/it, loss=0.215, lr=4.32e-5, step=53]Epoch 0:  76%|███████▋  | 55/72 [02:13<00:38,  2.27s/it, loss=0.204, lr=4.4e-5, step=54] Epoch 0:  78%|███████▊  | 56/72 [02:16<00:36,  2.26s/it, loss=0.204, lr=4.4e-5, step=54]Epoch 0:  78%|███████▊  | 56/72 [02:16<00:36,  2.26s/it, loss=0.19, lr=4.48e-5, step=55]Epoch 0:  79%|███████▉  | 57/72 [02:18<00:34,  2.29s/it, loss=0.19, lr=4.48e-5, step=55]Epoch 0:  79%|███████▉  | 57/72 [02:18<00:34,  2.29s/it, loss=0.179, lr=4.56e-5, step=56]Epoch 0:  81%|████████  | 58/72 [02:20<00:32,  2.33s/it, loss=0.179, lr=4.56e-5, step=56]Epoch 0:  81%|████████  | 58/72 [02:20<00:32,  2.33s/it, loss=0.208, lr=4.64e-5, step=57]Epoch 0:  82%|████████▏ | 59/72 [02:23<00:29,  2.31s/it, loss=0.208, lr=4.64e-5, step=57]Epoch 0:  82%|████████▏ | 59/72 [02:23<00:29,  2.31s/it, loss=0.164, lr=4.72e-5, step=58]Epoch 0:  83%|████████▎ | 60/72 [02:25<00:27,  2.30s/it, loss=0.164, lr=4.72e-5, step=58]Epoch 0:  83%|████████▎ | 60/72 [02:25<00:27,  2.30s/it, loss=0.149, lr=4.8e-5, step=59] Epoch 0:  85%|████████▍ | 61/72 [02:27<00:24,  2.26s/it, loss=0.149, lr=4.8e-5, step=59]Epoch 0:  85%|████████▍ | 61/72 [02:27<00:24,  2.26s/it, loss=0.146, lr=4.88e-5, step=60]Epoch 0:  86%|████████▌ | 62/72 [02:29<00:22,  2.26s/it, loss=0.146, lr=4.88e-5, step=60]Epoch 0:  86%|████████▌ | 62/72 [02:29<00:22,  2.26s/it, loss=0.204, lr=4.96e-5, step=61]Epoch 0:  88%|████████▊ | 63/72 [02:32<00:20,  2.31s/it, loss=0.204, lr=4.96e-5, step=61]Epoch 0:  88%|████████▊ | 63/72 [02:32<00:20,  2.31s/it, loss=0.123, lr=5.04e-5, step=62]Epoch 0:  89%|████████▉ | 64/72 [02:34<00:18,  2.30s/it, loss=0.123, lr=5.04e-5, step=62]Epoch 0:  89%|████████▉ | 64/72 [02:34<00:18,  2.30s/it, loss=0.117, lr=5.12e-5, step=63]Epoch 0:  90%|█████████ | 65/72 [02:36<00:15,  2.28s/it, loss=0.117, lr=5.12e-5, step=63]Epoch 0:  90%|█████████ | 65/72 [02:36<00:15,  2.28s/it, loss=0.636, lr=5.2e-5, step=64] Epoch 0:  92%|█████████▏| 66/72 [02:39<00:13,  2.29s/it, loss=0.636, lr=5.2e-5, step=64]Epoch 0:  92%|█████████▏| 66/72 [02:39<00:13,  2.29s/it, loss=0.896, lr=5.28e-5, step=65]Epoch 0:  93%|█████████▎| 67/72 [02:41<00:11,  2.30s/it, loss=0.896, lr=5.28e-5, step=65]Epoch 0:  93%|█████████▎| 67/72 [02:41<00:11,  2.30s/it, loss=0.0953, lr=5.36e-5, step=66]Epoch 0:  94%|█████████▍| 68/72 [02:43<00:09,  2.28s/it, loss=0.0953, lr=5.36e-5, step=66]Epoch 0:  94%|█████████▍| 68/72 [02:43<00:09,  2.28s/it, loss=0.0877, lr=5.44e-5, step=67]Epoch 0:  96%|█████████▌| 69/72 [02:45<00:06,  2.26s/it, loss=0.0877, lr=5.44e-5, step=67]Epoch 0:  96%|█████████▌| 69/72 [02:45<00:06,  2.26s/it, loss=0.133, lr=5.52e-5, step=68] Epoch 0:  97%|█████████▋| 70/72 [02:48<00:04,  2.27s/it, loss=0.133, lr=5.52e-5, step=68]Epoch 0:  97%|█████████▋| 70/72 [02:48<00:04,  2.27s/it, loss=0.0782, lr=5.6e-5, step=69]Epoch 0:  99%|█████████▊| 71/72 [02:50<00:02,  2.26s/it, loss=0.0782, lr=5.6e-5, step=69]Epoch 0:  99%|█████████▊| 71/72 [02:50<00:02,  2.26s/it, loss=0.075, lr=5.68e-5, step=70]Epoch 0: 100%|██████████| 72/72 [02:52<00:00,  2.25s/it, loss=0.075, lr=5.68e-5, step=70]Epoch 0: 100%|██████████| 72/72 [02:52<00:00,  2.25s/it, loss=0.198, lr=5.76e-5, step=71]Epoch 0: 100%|██████████| 72/72 [02:52<00:00,  2.40s/it, loss=0.198, lr=5.76e-5, step=71]
